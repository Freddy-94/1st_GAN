{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVgVDodws44avfRWInvuDS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Freddy-94/1st_GAN/blob/main/First_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alfredo Bernal Luna\n",
        "### August 4th 2024\n",
        "### First GAN implementation"
      ],
      "metadata": {
        "id": "dj-nL-h3rL8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the packages and libraries needed to run the model:"
      ],
      "metadata": {
        "id": "gZdWrdPernSW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VRmDaTGrqqK1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second, we specify the input dimensions of our model and dataset. Each image in MNIST is 28 × 28 pixels with a single channel (because the images are grayscale). The variable z_dim sets the size of the noise vector, z:"
      ],
      "metadata": {
        "id": "FqOcs2gPt4Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "\n",
        "# Input image dimensions\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "# Size of the noise vector, used as input to the Generator\n",
        "z_dim = 100"
      ],
      "metadata": {
        "id": "mjAyrxxVsmJa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator"
      ],
      "metadata": {
        "id": "PXqm_i3m5HM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(img_shape, z_dim):\n",
        "    model = Sequential()\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(128, input_dim=z_dim))\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    # Output layer with tanh activation\n",
        "    model.add(Dense(28 * 28 * 1, activation='tanh'))\n",
        "    # Reshape the Generator output to image dimensions\n",
        "    model.add(Reshape(img_shape))\n",
        "    return model"
      ],
      "metadata": {
        "id": "3MwGtR5XuiKR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator"
      ],
      "metadata": {
        "id": "-ARR9mA36TDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "    model = Sequential()\n",
        "    # Flatten the input image\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(128))\n",
        "    # Leaky ReLU activation\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    # Output layer with sigmoid activation\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "-fYl9Y7M6SJK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ],
      "metadata": {
        "id": "1QNTzBmm7FbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    model = Sequential()\n",
        "    # Combined Generator -> Discriminator model\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    return model"
      ],
      "metadata": {
        "id": "bIkEUWrl6Uia"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile the Discriminator\n",
        "discriminator = build_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Build the Generator\n",
        "generator = build_generator(img_shape, z_dim)\n",
        "\n",
        "# Keep Discriminator’s parameters constant for Generator training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build and compile GAN model with fixed Discriminator to train the Generator\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2smE8mU71He",
        "outputId": "4a4fdfe0-11f8-4d68-df56-0f79488f7b67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "DFjxpEzD-GYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "    # Load the MNIST dataset\n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "    X_train = X_train / 127.5 - 1.0\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # -------------------------\n",
        "        #  Train the Discriminator\n",
        "        # -------------------------\n",
        "\n",
        "        # Get a random batch of real images\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, 100))\n",
        "        gen_imgs = generator.predict(z)\n",
        "\n",
        "        # Train Discriminator\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, real)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "        d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train the Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, 100))\n",
        "        gen_imgs = generator.predict(z)\n",
        "\n",
        "        # Train Generator\n",
        "        g_loss = gan.train_on_batch(z, real)\n",
        "\n",
        "        if (iteration + 1) % sample_interval == 0:\n",
        "\n",
        "            # Save losses and accuracies so they can be plotted after training\n",
        "            losses.append((d_loss, g_loss))\n",
        "            accuracies.append(100.0 * accuracy)\n",
        "            iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "            # Output training progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "                  (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n",
        "\n",
        "            # Output a sample of generated image\n",
        "            sample_images(generator)"
      ],
      "metadata": {
        "id": "kGmOgGSc7-A1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict(z)\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(4, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1"
      ],
      "metadata": {
        "id": "egiDKg8j-Zis"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWA4xs_s-mIG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}